# -*- coding: utf-8 -*-

import re
import time

import requests
from bs4 import BeautifulSoup as bs


class GetCompanyInfoMixin:
    """
    各求人媒体より企業情報を取得する基底クラス
    """
    def __init__(self, base_url, interval, *args, **kwargs):
        # 媒体のベースURL
        self.BASE_URL = base_url
        # ページ取得の間隔(秒)
        self.INTERVAL_TIME = interval

    def parseHtml(self, url_):
        """
        htmlのパース
        """
        # インターバル
        time.sleep(self.INTERVAL_TIME)
        # 対象ページのHTMLの取得
        response = requests.get(url=url_)
        # 文字化け対策
        response.encoding = response.apparent_encoding
        # htmlのパース
        return bs(response.text, "html.parser")
    

    def output_data(self, filename_, data_list):
        with open(filename_, mode="a", encoding="UTF-8") as fw:
            fw.write("\n".join(data_list))
        


class GetCompanyInfoType(GetCompanyInfoMixin):
    """
    @typeから企業情報を取得するクラス
    """
    # 【】や()の文字列を検出するパターン
    PTN = "(.+)(【|（)(.+)(】|）)"


    def __init__(self, interval=5, *args, **kwargs):
        super().__init__(
                "https://type.jp", interval, *args, **kwargs)
        # 検索キーワード
        keyword = kwargs.get("keyword")
        if keyword:
            # 検索用URLを作成
            self.SEARCH_PAGE_URL = "{url}/job/search.do?/keyword={keyword}"\
                        .format(url=self.BASE_URL, keyword=keyword)
        else:
            # キーワードなしエラー
            pass

    
    def _remove_other_company_name(self, company_name):
        """
        会社名のみを取得
        """
        # 会社名をスペースで分離
        company_name_list = company_name.split()
        # 会社名を取得
        c_name = company_name_list.pop(0)
        # （）などの余計な文字列を削除
        result = re.match(self.PTN, c_name)
        if result:
            # （）書きは削除
            c_name = result.group(1)
        return c_name


    def _create_company_name_list(self, url_, output_list):
        # 会社一覧ページをパース
        soup = self.parseHtml(url_=url_)
        company_name_list = []
        for elem in soup.find_all("p", class_="company"):
            company_name = elem.find("span")
            if company_name:
                # 会社名がnullではない
                conpany_name_text = company_name.text
                # 会社名以外の文字列を削除
                conpany_name_text = self._remove_other_company_name(conpany_name_text)
                if conpany_name_text not in output_list:
                    # 重複なし
                    company_name_list.append(conpany_name_text)
        return company_name_list


    def _get_next_page_url(self, url_):
        """
        次のページ用のURLを取得
        """
        soup = self.parseHtml(url_=url_)
        p_next = soup.find("p", class_="next").find("a")
        nextpage = ""
        if p_next:
            # 次のページのURLが存在する
            nextpage = p_next.get("href")
        if nextpage:
            # 基となるURLと次ページのURLを合わせる
            nextpage = "{base_url}{next}"\
                .format(base_url=self.BASE_URL, next=nextpage)
        return nextpage


    def execute(self, output_flg=False):
        """
        会社名リスト作成を実行
        """
        output_company_list = []
        # 検索ページトップ画面の一覧から会社名を取得
        c_name_list = self._create_company_name_list(
                    url_=self.SEARCH_PAGE_URL, output_list=output_company_list)
        output_company_list.append(c_name_list)
        # 次のページURL取得
        next_url = self._get_next_page_url(url_=self.SEARCH_PAGE_URL)
        while next_url:
            output_company_list.append(
                    self._create_company_name_list(
                            url_=next_url, output_list=output_company_list))
            # 次のページURL取得
            next_url = self._get_next_page_url(url_=next_url)
            if not next_url:
                # 次のページがない場合、ループ終了
                break

        if output_flg:
            # 外部ファイルへの書き出し
            self.output_data(filename_="./temp.txt",
                    data_list=output_company_list)
        return output_company_list


if __name__ == "__main__":
    get_company_info_type = GetCompanyInfoType(keyword="IT", interval=2)
    _ = get_company_info_type.execute(output_flg=True)
